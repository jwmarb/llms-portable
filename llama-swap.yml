models:
  exaone-deep-32b:
    proxy: http://localhost:4377
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 4377
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      -ngl 99
      --model /home/josephmarbella/llms-portable/models/LGAI-EXAONE_EXAONE-Deep-32B-IQ3_XXS.gguf
      --ctx-size 32768
      -ngld 99
      --draft-max 12
      --draft-min 1
      --draft-p-min 0.6
      -md /home/josephmarbella/llms-portable/models/LGAI-EXAONE_EXAONE-Deep-2.4B-Q8_0.gguf
  exaone-deep-7.8b:
    proxy: http://localhost:4377
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 4377
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      -ngl 99
      --model /home/josephmarbella/llms-portable/models/LGAI-EXAONE_EXAONE-Deep-7.8B-Q4_K_M.gguf
      --ctx-size 32768
      -ngld 99
      --draft-max 12
      --draft-min 1
      --draft-p-min 0.6
      -md /home/josephmarbella/llms-portable/models/LGAI-EXAONE_EXAONE-Deep-2.4B-Q8_0.gguf
  exaone-deep-2.4b:
    proxy: http://localhost:4377
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 4377
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      -ngl 99
      --model /home/josephmarbella/llms-portable/models/LGAI-EXAONE_EXAONE-Deep-2.4B-Q8_0.gguf
      --ctx-size 32768
  phi-4-mini-instruct:
    proxy: http://localhost:4377
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 4377
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      -ngl 99
      --model /home/josephmarbella/llms-portable/models/microsoft_Phi-4-mini-instruct-Q8_0.gguf
      --ctx-size 131072
  olmo-2-0325-32b:
    proxy: http://localhost:4377
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 4377
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      -ngl 99
      --model /home/josephmarbella/llms-portable/models/OLMo-2-0325-32B-Instruct.i1-IQ3_S.gguf
      --ctx-size 4096
      -ngld 99
      --draft-max 12
      --draft-min 1
      --draft-p-min 0.6
      -md /home/josephmarbella/llms-portable/models/OLMo-2-1124-7B-Instruct-IQ4_XS.gguf
  granite-vision-3.2-2b:
    proxy: http://localhost:4377
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 4377
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      -ngl 99
      --model /home/josephmarbella/llms-portable/models/ibm-granite_granite-vision-3.2-2b-Q8_0.gguf
      --ctx-size 131072
  reka-flash-3:
    proxy: http://localhost:4377
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 4377
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      -ngl 99
      --model /home/josephmarbella/llms-portable/models/RekaAI_reka-flash-3-IQ4_XS.gguf
      --ctx-size 32768
  granite-3.2-8b:
    proxy: http://localhost:4377
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 4377
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      -ngl 99
      --model /home/josephmarbella/llms-portable/models/ibm-granite_granite-3.2-8b-instruct-Q4_K_M.gguf
      --ctx-size 32768
      -ngld 99
      --draft-max 12
      --draft-min 1
      --draft-p-min 0.6
      -md /home/josephmarbella/llms-portable/models/ibm-granite_granite-3.2-2b-instruct-Q8_0.gguf
  phi-4:
    proxy: http://localhost:4377
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 4377
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      -ngl 99
      --model /home/josephmarbella/llms-portable/models/phi-4-IQ4_XS.gguf
      --ctx-size 16384
  olympiccoder-32b:
    proxy: http://localhost:4377
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 4377
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      -ngl 99
      --model /home/josephmarbella/llms-portable/models/open-r1_OlympicCoder-32B-IQ3_XXS.gguf
      --temp 0.7
      --top-k 50
      --top-p 0.95
      -ngld 99
      --draft-max 12
      --draft-min 1
      --draft-p-min 0.6
      -md /home/josephmarbella/llms-portable/models/Qwen2.5-Coder-0.5B-Instruct-Q8_0.gguf
      --ctx-size 32768
  llama3.2-reasoning-1b:
    proxy: http://localhost:4377
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 4377
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      -ngl 99
      --model /home/josephmarbella/llms-portable/models/Reasoning-Llama-1b-v0.1-Q8_0.gguf
      --ctx-size 8192
      --temp 0.7
      --top-k 50
      --top-p 0.95
  llama3.1-nemotron-nano-8b:
    proxy: http://localhost:4377
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 4377
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      -ngl 99
      --model /home/josephmarbella/llms-portable/models/Llama-3.1-Nemotron-Nano-8B-v1-Q4_K_M.gguf
      -ngld 99
      --draft-max 12
      --draft-min 1
      --draft-p-min 0.6
      -md /home/josephmarbella/llms-portable/models/Reasoning-Llama-1b-v0.1-Q8_0.gguf
      --ctx-size 131072
      --temp 0.7
      --top-k 50
      --top-p 0.95
  llama3.2-3b:
    proxy: http://localhost:4377
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 4377
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      -ngl 99
      --model /home/josephmarbella/llms-portable/models/Llama-3.2-3B-Instruct-Q8_0.gguf
      -ngld 99
      --draft-max 12
      --draft-min 1
      --draft-p-min 0.6
      -md /home/josephmarbella/llms-portable/models/Llama-3.2-1B-Instruct-Q8_0.gguf
      --ctx-size 131072
  llama3.2-1b:
    proxy: http://localhost:4377
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 4377
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      -ngl 99
      --model /home/josephmarbella/llms-portable/models/Llama-3.2-1B-Instruct-Q8_0.gguf
      --ctx-size 131072
  mistral-small-24b:
    proxy: http://localhost:4377
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 4377
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      -ngl 99
      --model /home/josephmarbella/llms-portable/models/Mistral-Small-24B-Instruct-2501-IQ4_XS.gguf
      --ctx-size 32768
      --temp 0.15
  mistral-small-3.1-24b:
    proxy: http://localhost:4377
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 4377
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      -ngl 99
      --model /home/josephmarbella/llms-portable/models/mistralai_Mistral-Small-3.1-24B-Instruct-2503-IQ4_XS.gguf
      --ctx-size 32768
      --temp 0.15
  gemma3-27b:
    proxy: http://localhost:4377
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 4377
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      -ngl 99
      --model /home/josephmarbella/llms-portable/models/google_gemma-3-27b-it-IQ4_XS.gguf
      -ngld 99
      --draft-max 12
      --draft-min 1
      --draft-p-min 0.6
      -md /home/josephmarbella/llms-portable/models/google_gemma-3-1b-it-Q8_0.gguf
      --ctx-size 8192
  gemma3-12b:
    proxy: http://localhost:4377
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 4377
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      -ngl 99
      --model /home/josephmarbella/llms-portable/models/google_gemma-3-12b-it-Q4_K_M.gguf
      -ngld 99
      --draft-max 12
      --draft-min 1
      --draft-p-min 0.6
      -md /home/josephmarbella/llms-portable/models/google_gemma-3-1b-it-Q8_0.gguf
      --ctx-size 32768
  gemma3-4b:
    proxy: http://localhost:4377
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 4377
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      -ngl 99
      --model /home/josephmarbella/llms-portable/models/google_gemma-3-4b-it-Q8_0.gguf
      --ctx-size 131072
  gemma3-1b:
    proxy: http://localhost:4377
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 4377
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      -ngl 99
      --model /home/josephmarbella/llms-portable/models/google_gemma-3-1b-it-Q8_0.gguf
      --ctx-size 32768
  qwen2.5-coder-7b:
    proxy: http://localhost:8371
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 8371
      --model /home/josephmarbella/llms-portable/models/Qwen2.5.1-Coder-7B-Instruct-Q4_K_M.gguf
      -md /home/josephmarbella/llms-portable/models/Qwen2.5-Coder-0.5B-Instruct-Q8_0.gguf
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      -ngl 99
      -ngld 99
      --draft-max 20
      --draft-min 1
      --draft-p-min 0.6
      --ctx-size 16384
      --parallel 2
  gte-qwen2-1.5b-instruct:
    proxy: http://localhost:8372
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 8372
      --model /home/josephmarbella/llms-portable/models/gte-Qwen2-1.5B-instruct.Q8_0.gguf
      -ngl 99
      --embedding
      --ctx-size 32768
      --pooling cls
      # --ubatch-size 1536
      --ubatch-size 32768
      --parallel 8
  gte-qwen2-7b-instruct:
    proxy: http://localhost:8372
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 8372
      --model /home/josephmarbella/llms-portable/models/gte-Qwen2-7B-instruct-Q4_K_M.gguf
      -ngl 99
      --embeddings
      --ctx-size 32768
      --pooling rank
      --ubatch-size 4096
  readerlm-v2:
    proxy: http://localhost:8373
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 8373
      --model /home/josephmarbella/llms-portable/models/reader-lm-1.5b-Q8_0.gguf
      -ngl 99
      --flash-attn
      --cache-type-k q8_0
      --cache-type-v q8_0
      # --ctx-size 262144
      --ctx-size 256000
      --temp 0.0
      --top-k 50
      --repeat-penalty 1.13
      --presence-penalty 0.25
      --frequency-penalty 0.25
      --batch-size 32768
  multilingual-e5-large-instruct:
    proxy: http://localhost:8375
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 8375
      --model /home/josephmarbella/llms-portable/models/multilingual-e5-large-instruct-q8_0.gguf
      --embeddings
      -ngl 99
      --ctx-size 514
  multilingual-e5-large:
    proxy: http://localhost:8376
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 8376
      --model /home/josephmarbella/llms-portable/models/multilingual-e5-large-q8_0.gguf
      --embeddings
      -ngl 99
      --ctx-size 1024
      --ubatch-size 512
  multilingual-e5-large-cpu:
    proxy: http://localhost:8377
    cmd: >
      /home/josephmarbella/llms-portable/llama.cpp/build/bin/llama-server
      --port 8377
      --model /home/josephmarbella/llms-portable/models/multilingual-e5-large-q8_0.gguf
      --embeddings
      --ctx-size 3072
      --parallel 6
      --ubatch-size 3072
      --prio 2
      --threads 112
profiles:
  coding:
    - "qwen2.5-coder-7b"
    - "multilingual-e5-large-cpu"
    - "multilingual-e5-large"
    - "readerlm-v2"
