services:
  reranker:
    restart: always
    container_name: reranker
    image: ghcr.io/huggingface/text-embeddings-inference:latest
    ports:
      - 8374:80
    volumes:
      - ./models/.cache:/data
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
    command:
      - "--model-id=BAAI/bge-reranker-v2-m3"
  openai-edge-tts:
    restart: always
    image: travisvn/openai-edge-tts:latest
    container_name: openai-edge-tts
    ports:
      - 5050:5050
    environment:
      - REQUIRE_API_KEY=False
  speaches:
    container_name: speaches
    ports:
      - 8000:8000
    restart: always
    image: ghcr.io/speaches-ai/speaches:latest-cuda
    build:
      args:
        BASE_IMAGE: nvidia/cuda:12.6.3-cudnn-runtime-ubuntu24.04
    volumes:
      - ./models/.cache:/home/ubuntu/.cache
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://0.0.0.0:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s
  tika:
    container_name: tika
    image: apache/tika:latest
    ports:
      - 9998:9998
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
  searxng:
    container_name: searxng
    image: searxng/searxng:latest
    ports:
      - 8889:8080
    volumes:
      - ./data/searxng:/etc/searxng:rw
    restart: always
